% arara: pdflatex: { options: ['-synctex=1', '-interaction=nonstopmode'] }
% arara: pdflatex: { options: ['-synctex=1', '-interaction=nonstopmode'] }

%%%
% File: ./cover_letter.tex
% Created Date: Tuesday, February 11th, 2025
% Author: Zihan Wu
% -----
% Last Modified: Tuesday, 11th February 2025 12:16:28 pm
% Modified By: the developer formerly known as Zihan at <wzh4464@gmail.com>
% -----
% HISTORY:
% Date      		By   	Comments
% ----------		------	---------------------------------------------------------
%%%
\documentclass[11pt]{letter}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=1in}
\signature{Zihan Wu\\
Department of Electrical Engineering\\
City University of Hong Kong\\
Hong Kong\\
Email: zihan.wu@my.cityu.edu.hk}
\begin{document}
\begin{letter}{Editor-in-Chief\\
IEEE Transactions on Systems, Man, and Cybernetics: Systems}

\opening{Dear Editor,}

We are pleased to resubmit our revised manuscript titled ``DiMergeCo: A Scalable Framework for Large-Scale Co-Clustering with Theoretical Guarantees'' (Manuscript ID: SMCA-25-02-0634) for consideration in \emph{IEEE Transactions on Systems, Man, and Cybernetics: Systems}.

We sincerely thank the Senior Editor, Associate Editor, and three reviewers for their constructive feedback and valuable suggestions. Their insights have significantly enhanced the quality and rigor of our work. We have carefully addressed all concerns raised during the review process through substantial revisions, resulting in a significantly strengthened manuscript.

\textbf{Major Revisions Addressing Reviewer Concerns:}

\begin{enumerate}
\item \textbf{Enhanced Theoretical Foundations:} We have added complete mathematical proofs for all theorems, explicit assumptions with sensitivity analysis, and rigorous convergence guarantees. The revised manuscript now includes six formal assumptions (Independence, Minimum-block resolution, Density coherence, Finite K, Sample-size requirements) with detailed mathematical derivations in both the main text and supplementary materials.

\item \textbf{Multi-Domain Experimental Validation:} Following reviewer suggestions, we have expanded our evaluation beyond text datasets to include recommendation systems (Amazon dataset with 123,321 users and 23,379 products) and bioinformatics applications (Breast Cancer Wisconsin dataset with 130 samples and 11,731 genes). This demonstrates the broad applicability of our framework across diverse data types and matrix structures.

\item \textbf{Comprehensive Parameter Sensitivity Analysis:} We have added a detailed ablation study examining 36 parameter combinations across key hyperparameters (block configurations, co-cluster size thresholds, and detection probability thresholds). This analysis provides evidence-based guidelines for parameter selection and demonstrates the robustness of our approach.

\item \textbf{Enhanced Implementation Details:} We have significantly expanded the MPI implementation section with detailed protocols for data distribution, hierarchical communication management achieving O(log P) complexity, and comprehensive reproducibility guidelines.

\item \textbf{Expanded Related Work:} Following specific reviewer suggestions, we have added a new subsection on co-clustering applications in medical image analysis, incorporating the five suggested references and demonstrating the relevance of our scalable approach to medical imaging applications.

\item \textbf{Improved Presentation:} We have added a comprehensive notation table for better readability and enhanced all figures with proper axis labels, legends, and self-contained captions.
\end{enumerate}

\textbf{Specific Algorithmic Contributions Addressed:}

In response to concerns about algorithmic novelty, we have clarified our three fundamental innovations:
\begin{itemize}
\item \textbf{Theoretically-Guaranteed Probabilistic Partitioning:} The first matrix partitioning algorithm specifically designed for co-cluster preservation with adaptive block sizing and explicit probabilistic guarantees.
\item \textbf{Communication-Optimal Hierarchical Merging:} A binary tree-based coordination eliminating centralized bottlenecks and reducing communication complexity from O(n) to O(log n).
\item \textbf{Integrated Framework with Theoretical Foundations:} Complete theoretical analysis connecting local solution quality to global optimality bounds with rigorous performance guarantees.
\end{itemize}

\textbf{Enhanced Experimental Validation:}

Our revised experiments now demonstrate:
\begin{itemize}
\item 83\% computational time reduction on dense matrices
\item Superior performance across three distinct domains (text analysis, recommendation systems, genomics)
\item Scalability to datasets with 685K samples
\item Effective small co-cluster detection with coordinated protection mechanisms
\item Comprehensive parameter sensitivity analysis with practical guidelines
\end{itemize}

\textbf{Theoretical Rigor:}

The revised manuscript provides complete mathematical foundations including:
\begin{itemize}
\item Formal proofs for co-cluster preservation probability bounds
\item Global solution quality bounds with detailed derivations
\item Convergence guarantees for hierarchical merging
\item Assumption sensitivity analysis demonstrating theoretical robustness
\end{itemize}

This work makes significant contributions to large-scale data analysis by providing the first scalable co-clustering framework with provable theoretical guarantees. The method addresses critical challenges in processing massive datasets (millions of samples and features) while maintaining clustering quality, making it highly relevant to the systems and cybernetics community served by TSMC-S.

We believe the substantially revised manuscript now addresses all reviewer concerns and provides a rigorous, well-validated framework for large-scale co-clustering. The comprehensive theoretical foundations, multi-domain experimental validation, and detailed implementation guidelines make this work a valuable contribution to the field.

We appreciate your consideration of our revised submission and look forward to your feedback.

\closing{Best regards,}

\end{letter}
\end{document}