% arara: latexmk: { options: ["-cd", "-outdir=../build/response"] }


% Reviewer Response Letter for DiMergeCo Paper â€“ Round 2
% Copyright (C) 2025

\documentclass{ar2rc}
\usepackage{bm}
\usepackage{amsfonts,amssymb}
\usepackage{makecell}
\usepackage{tabularx}
\usepackage{supertabular}
\usepackage{caption}
\usepackage{bbding}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{tabularray}
\usepackage{array}
\usepackage{xr}
\externaldocument{../build/root/root}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{longtable}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{threeparttable}
\usepackage{textcomp}
\usepackage{float}
\usepackage{subcaption}
\usepackage[italian,english]{babel}
\usepackage{csquotes}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\newtheorem*{theorem*}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{proposition*}{Proposition}
\newtheorem*{corollary*}{Corollary}

\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\newtheorem*{definition*}{Definition}
\newtheorem*{example*}{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}

\newtheorem*{remark*}{Remark}
\newtheorem*{assumption*}{Assumption}

% Cref for lemma
\crefname{lemma}{lemma}{lemmas}
\Crefname{lemma}{Lemma}{Lemmas}
\crefname{assumption}{assumption}{assumptions}
\Crefname{assumption}{Assumption}{Assumptions}
\crefname{definition}{definition}{definitions}
\Crefname{definition}{Definition}{Definitions}
\crefname{corollary}{corollary}{corollaries}
\Crefname{corollary}{Corollary}{Corollaries}
\crefname{proposition}{proposition}{propositions}
\Crefname{proposition}{Proposition}{Propositions}
\crefname{theorem}{theorem}{theorems}
\Crefname{theorem}{Theorem}{Theorems}

\newcommand{\change}[1]{\textcolor{blue}{#1}}
\newcommand{\todo}[1]{\textcolor{red}{#1}}
\usepackage{xspace}
% bibliography
\usepackage[backend=biber,style=ieee]{biblatex}
\bibliography{references}
% Suppress 'url' field in 'article' entries but keep 'doi'
\renewbibmacro*{doi+eprint+url}{%
  \iftoggle{bbx:doi}
    {\printfield{doi}} % keep doi
    {}%
  \iftoggle{bbx:eprint}
    {\usebibmacro{eprint}}
    {}%
  \iftoggle{bbx:url}
    {} % suppress url
    {}%
}
% Suppress 'isbn' field
\AtEveryBibitem{%
  \ifentrytype{book}{}{\clearfield{isbn}}
}
% Suppress 'issn' field
\AtEveryBibitem{%
  \clearfield{issn}
}

% add doi if available
\DeclareFieldFormat{doi}{%
  \iffieldundef{doi}{%
  }{%
    \mkbibacro{DOI}\addcolon\space
    \ifhyperref
      {\href{https://doi.org/#1}{\nolinkurl{#1}}}
      {\nolinkurl{#1}}%
  }%
}

\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}
\def\etal{\emph{et al}\onedot}
\makeatother

\usepackage{pifont}
\graphicspath{{images/}}
\renewcommand{\cite}[1]{~\autocite{#1}}

\title{
DiMergeCo: A Scalable Framework for Large-Scale Co-Clustering with Theoretical Guarantees}
\author{Zihan Wu, Zhaoke Huang, Hong Yan}
\journal{Manuscript Resubmitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems\\}
\doi{\mbox{Original Submission Number: SMCA-25-02-0634}}

% equation/figure/table/theorem numbering (continue from main paper)
\setcounter{equation}{27}
\setcounter{figure}{4}
\setcounter{table}{5}
\setcounter{theorem}{8}

\begin{document}

\maketitle

\noindent
The authors extend their sincere gratitude to the Senior Editor, Associate Editor and reviewers for their thorough and constructive evaluation during the second round of review. We greatly appreciate the specific, actionable suggestions, which have led to substantial improvements in the theoretical foundations, experimental rigor, and presentation of our manuscript.

In this revised manuscript, we have comprehensively addressed all seven reviewer comments. The major revisions include: (1)~a new \emph{Conditional Merging Quality Bound} theorem with proof, supported by an ablation study of five merging strategies; (2)~unified mathematical notation throughout; (3)~experimental results reported as mean $\pm$ standard deviation over 10 seeds with statistical significance tests; (4)~a new memory profiling table; (5)~a scalability comparison with PNMTF; (6)~a modern baseline (SpectralCoclustering from scikit-learn); and (7)~clarification of the ``Amazon 1000'' dataset.

All modifications in the manuscript are highlighted in {\color{blue}blue}.

%====================================== Editorial Comments ============================================

\section{Editorial Comments}

\paragraph{Senior Editor} \textbf{\color{blue}\textit{All reviewers have noted some remaining issues. A second round of major revision is recommended.}}

\AR{We thank the Senior Editor for the opportunity to further strengthen our manuscript. We have carefully addressed every point raised by both reviewers, as detailed below.}

\paragraph{Associate Editor} \textbf{\color{blue}\textit{Both reviewers have acknowledged improvements from the first revision but identify remaining concerns regarding theoretical rigor of the merging step, notation consistency, statistical reporting, and baseline selection. Please address these in a revised version.}}

\AR{We sincerely thank the Associate Editor for the clear summary. We have systematically addressed all concerns: theoretical gaps are now closed with a conditional merging quality bound and supporting ablation study; notation is unified; results are reported with proper statistical measures; and a modern baseline is added. Detailed responses follow.}

%====================================== Reviewer 1 ============================================

\section{Reviewer \#1}

\RC{The authors have addressed many of my earlier concerns satisfactorily. I appreciate the expanded experiments and parameter sensitivity analysis. However, several issues remain before I can recommend acceptance.}

\AR{We thank the reviewer for their continued engagement and constructive feedback. We have addressed all remaining concerns as detailed below.}

%--- RC1: Statistical significance ---
\RC{1. The experimental results in Table~I are reported as single-run numbers. For a journal submission, results should be reported as mean $\pm$ standard deviation over multiple random seeds, with statistical significance tests (e.g., paired $t$-tests).}

\AR{We fully agree. In the revised manuscript, \textbf{all results in Table~I} (\Cref{tab:evaluation-metrics}) are now reported as mean $\pm$ standard deviation over 10 independent runs with different random seeds. We have also added a table footnote reporting paired $t$-test results confirming that DiMergeCo-SCC significantly outperforms each baseline ($p < 0.01$) on all datasets where both methods produce results.}

\paragraph{Manuscript Modifications}
\begin{quote}
\Cref{tab:evaluation-metrics} has been reformatted to show mean $\pm$ std over 10 seeds. A footnote states: ``Paired $t$-tests confirm that DiMergeCo-SCC significantly outperforms each baseline ($p < 0.01$) on all datasets where both methods produce results.''
\end{quote}

%--- RC2: Scalability comparison with PNMTF ---
\RC{2. The scalability analysis (Section 6.4) only shows DiMergeCo's efficiency curve. For a convincing comparison, please include the scalability curve of PNMTF (the main distributed baseline) alongside DiMergeCo to demonstrate the claimed $O(\log n)$ vs.\ $O(n)$ communication advantage.}

\AR{We have added a direct scalability comparison. The new \Cref{fig:scalability-comparison} plots wall-clock time as a function of the number of processing nodes for both DiMergeCo-PNMTF and PNMTF on the Amazon and CLASSIC4 datasets. DiMergeCo achieves consistently lower execution times across all node counts, with the gap widening at higher parallelization levels due to its $O(\log n)$ communication complexity versus PNMTF's $O(n)$.}

\paragraph{Manuscript Modifications}
\begin{quote}
A new subsubsection ``Comparison with PNMTF Scalability'' has been added in \Cref{subsec:scalability-analysis}, including \Cref{fig:scalability-comparison} showing the wall-clock time comparison.
\end{quote}

%--- RC3: Memory profiling ---
\RC{3. While running time comparisons are provided, memory usage is an equally important concern for large-scale methods. Please report peak memory consumption for each method and dataset.}

\AR{We have added a new memory profiling table. \Cref{tab:memory-usage} reports peak RSS (Resident Set Size) per node for all methods across all four datasets. Key findings: DiMergeCo reduces per-node memory by 5--8$\times$ compared to centralized baselines on large datasets, since each node only processes its assigned submatrix. Methods marked ``OOM'' exceeded the 128\,GB system RAM limit. For distributed methods (DiMergeCo, PNMTF), per-node peak memory is reported.}

\paragraph{Manuscript Modifications}
\begin{quote}
A new \Cref{tab:memory-usage} ``Peak Memory Usage (MB) for Various Co-clustering Methods on Selected Datasets'' has been added after \Cref{tab:running-time}.
\end{quote}

%--- RC4: Amazon 1000 clarification ---
\RC{4. In the scalability analysis, you reference ``Amazon 1000'' but never define what this means. Is it a different dataset from the Amazon dataset in Table~I? Please clarify.}

\AR{We apologize for the confusion. ``Amazon 1000'' denotes a \textbf{subset of 1,000 randomly sampled documents} from the full Amazon dataset (123,321 users). It is used specifically for controlled scalability profiling to isolate parallelization overhead from dataset-size effects. We have added an explicit footnote in the revised manuscript to clarify this.}

\paragraph{Manuscript Modifications}
\begin{quote}
A footnote has been added in \Cref{subsec:scalability-analysis}: ``Amazon 1000 denotes a subset of 1,000 randomly sampled documents from the full Amazon dataset (123,321 users), used here for controlled scalability profiling to isolate parallelization overhead from dataset-size effects.''
\end{quote}

%====================================== Reviewer 2 ============================================

\section{Reviewer \#2}

\RC{The paper has been substantially improved since the first submission, particularly in the theoretical analysis and multi-domain experiments. However, I have three remaining concerns that should be addressed.}

\AR{We thank the reviewer for acknowledging the improvements. We have addressed all three remaining concerns as follows.}

%--- RC1: Theoretical gap in merging ---
\RC{1. The remark after Theorem~5 acknowledges that the merging step is ``a heuristic'' with no theoretical guarantee. This is a significant gap: the paper claims ``theoretical guarantees'' in the title, but the merging step---a core component---lacks any formal analysis. At minimum, please provide a conditional guarantee or clearly discuss the limitations.}

\AR{This is an important observation, and we have substantially strengthened the theoretical analysis. We now provide:

\begin{enumerate}
    \item \textbf{A new Conditional Merging Quality Bound} (\Cref{thm:merging-quality}): Under two verifiable conditions---bounded partition overlap ($\tau$) and local $\epsilon$-suboptimality---the merging error is bounded by $J(\mathcal{C}_{\mathrm{merge}}) \leq J(\mathcal{C}^*) + P\epsilon + \tau \cdot |\mathcal{B}|$. Crucially, the probabilistic partitioning algorithm (\Cref{thm:probability-co-cluster-detection}) is designed to minimize $|\mathcal{B}|$, tightening this bound.

    \item \textbf{An updated Remark} (Remark~1) that replaces the previous ``heuristic'' characterization with a reference to the new theorem and the ablation study.

    \item \textbf{A Discussion paragraph} at the end of Section~5 that honestly acknowledges unconditional approximation ratios as an open problem (common in hierarchical clustering\cite{dasgupta2016CostFunctionClustering}) while explaining how our conditional guarantee is both meaningful and empirically validated.

    \item \textbf{A comprehensive ablation study} (\Cref{subsec:ablation}) comparing five merging strategies across three datasets, providing empirical validation that the conditions of \Cref{thm:merging-quality} are satisfied in practice and that hierarchical merging outperforms alternatives.
\end{enumerate}

The full proof is provided in the supplementary material.
}

\paragraph{Manuscript Modifications}
\begin{quote}
\textbf{Section~5 (Theoretical Analysis):} Added \Cref{thm:merging-quality} (Conditional Merging Quality Bound) with proof sketch after Theorem~5. Replaced the previous Remark~1 with Remark~1 (Merging Strategy Analysis). Added ``Discussion on Theoretical Guarantees'' paragraph. Updated ``Conclusion and Practical Considerations'' to reference the new theorem.

\textbf{Supplementary material:} Added full proof of \Cref{thm:merging-quality} in a new subsection ``Proof of Conditional Merging Quality Bound.''

\textbf{Section~6 (Experiments):} Added \Cref{subsec:ablation} ``Ablation Study: Merging Strategy'' with three components: (a)~\Cref{tab:merging-quality} comparing NMI/ARI for 5 strategies $\times$ 3 datasets; (b)~\Cref{tab:merging-cost} comparing communication and time costs; (c)~\Cref{fig:merging-convergence} showing objective function convergence.
\end{quote}

%--- RC2: Notation inconsistencies ---
\RC{2. There are notation inconsistencies throughout the manuscript: (a)~the data matrix is sometimes written as plain $A$ instead of $\mathbf{A}$; (b)~the notation table uses bold $\mathbf{C}_k$ for co-clusters while the body text uses non-bold $C_k$. Please unify.}

\AR{We have systematically unified all notation:

\begin{enumerate}
    \item \textbf{Data matrix:} All occurrences of plain ``$A$'' referring to the data matrix have been changed to ``$\mathbf{A}$'' (three instances in \Cref{subsec:problem-statement}, \Cref{alg:method}, and \Cref{subsec:large-matrix-partitioning}).

    \item \textbf{Co-cluster notation:} The notation table (\Cref{tab:notation}) has been updated to use non-bold ``$C_k$'' consistently, matching the body text convention. All six affected entries in the table have been corrected.
\end{enumerate}
}

\paragraph{Manuscript Modifications}
\begin{quote}
\Cref{tab:notation}: Changed $\mathbf{C}_k$ to $C_k$ in all six affected rows (co-cluster set, individual co-cluster, co-cluster sizes, detection probability, block sizes, overlapping blocks).

Body text: Changed three instances of plain $A$ to $\mathbf{A}$ in \Cref{subsec:problem-statement} (Eq.~1 context), \Cref{alg:method} (Line~6), and \Cref{subsec:large-matrix-partitioning} (partitioning description).
\end{quote}

%--- RC3: Modern baselines ---
\RC{3. The compared baselines are somewhat dated (SCC from 2001, NMTF from 2005). Please consider adding at least one more recent baseline (e.g., scikit-learn's SpectralBiclustering or SpectralCoclustering) to demonstrate that your advantages hold against modern implementations.}

\AR{We have added \textbf{SpectralCoclustering} from scikit-learn\cite{sklearn2011} as a modern baseline in all experimental tables. As expected, SpectralCoclustering achieves competitive quality on small datasets (CLASSIC4: NMI = 0.891, BCW: NMI = 0.702) but fails (OOM) on large datasets (Amazon, RCV1-Large), reinforcing DiMergeCo's scalability advantage.

We have also added a ``Modern Baseline Selection'' paragraph in Related Work explaining why deep learning-based methods (e.g., DeepCC\cite{dongkuanxu2019DeepCoClustering}) are not directly comparable: they target different data modalities (images) and lack distributed implementations.}

\paragraph{Manuscript Modifications}
\begin{quote}
\textbf{\Cref{tab:evaluation-metrics}:} Added a ``SpectralCC'' column with results on CLASSIC4 and BCW; marked ``*'' (OOM) on Amazon and RCV1-Large.

\textbf{\Cref{tab:memory-usage}:} Added SpectralCC memory usage.

\textbf{Compared Methods (\Cref{sec:experiment}):} Added description of SpectralCoclustering.

\textbf{Related Work (\Cref{sec:related-work}):} Added ``Modern Baseline Selection'' paragraph with references to recent surveys\cite{pontes2015BiclusteringReviewSurvey, zhao2021CoclusteringReviewAdvances}.
\end{quote}

%====================================== Summary ============================================

\section{Summary of Major Revisions}

We have comprehensively addressed all reviewer concerns through the following major revisions:

\begin{enumerate}
    \item \textbf{Conditional Merging Quality Bound (Reviewer~2, RC1):} New \Cref{thm:merging-quality} with proof in supplementary material, providing the first formal guarantee for the merging step under verifiable conditions ensured by design.

    \item \textbf{Ablation Study (Reviewer~2, RC1):} New \Cref{subsec:ablation} comparing five merging strategies with quality, communication cost, and convergence analysis across three datasets, empirically validating the theoretical bound.

    \item \textbf{Statistical Reporting (Reviewer~1, RC1):} All results in \Cref{tab:evaluation-metrics} now report mean $\pm$ std over 10 seeds with paired $t$-test significance.

    \item \textbf{Scalability Comparison (Reviewer~1, RC2):} New \Cref{fig:scalability-comparison} directly comparing DiMergeCo vs.\ PNMTF scalability curves.

    \item \textbf{Memory Profiling (Reviewer~1, RC3):} New \Cref{tab:memory-usage} reporting peak memory per method per dataset.

    \item \textbf{Amazon 1000 Clarification (Reviewer~1, RC4):} Footnote added explaining the subset.

    \item \textbf{Notation Unification (Reviewer~2, RC2):} $\mathbf{A}$ for data matrix and $C_k$ for co-clusters used consistently throughout.

    \item \textbf{Modern Baseline (Reviewer~2, RC3):} SpectralCoclustering from scikit-learn added to all experimental tables with Related Work discussion.
\end{enumerate}

We believe these revisions have addressed all remaining concerns and significantly strengthened the manuscript's theoretical foundations and experimental rigor. We thank the reviewers for their thorough evaluation and look forward to their assessment of the revised version.

\printbibliography
\end{document}
