@article{chen2023ParallelNonNegativeMatrix,
  title        = {Parallel Non-Negative Matrix Tri-Factorization for Text Data Co-Clustering},
  author       = {Chen, Yufu and Lei, Zhiqi and Rao, Yanghui and Xie, Haoran and Wang, Fu Lee and Yin, Jian and Li, Qing},
  date         = {2023-05},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume       = {35},
  number       = {5},
  pages        = {5132--5146},
  issn         = {1558-2191},
  doi          = {10.1109/TKDE.2022.3145489},
  abstract     = {As a novel paradigm for data mining and dimensionality reduction, Non-negative Matrix Tri-Factorization (NMTF) has attracted much attention due to its notable performance and elegant mathematical derivation, and it has been applied to a plethora of real-world applications, such as text data co-clustering. However, the existing NMTF-based methods usually involve intensive matrix multiplications, which exhibits a major limitation of high computational complexity. With the explosion at both the size and the feature dimension of texts, there is a growing need to develop a parallel and scalable NMTF-based algorithm for text data co-clustering. To this end, we first show in this paper how to theoretically derive the original optimization problem of NMTF by introducing the Lagrangian multipliers. Then, we propose to solve the Lagrange dual objective function in parallel through an efficient distributed implementation. Extensive experiments on five benchmark corpora validate the effectiveness, efficiency, and scalability of our distributed parallel update algorithm for an NMTF-based text data co-clustering method.},
  eventtitle   = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}}
}
@article{cheng2000BiclusteringExpressionData,
  title        = {Biclustering of {{Expression Data}}},
  author       = {Cheng, Yizong and Church, G.},
  date         = {2000},
  journaltitle = {Proceedings. International Conference on Intelligent Systems for Molecular Biology},
  shortjournal = {Proceedings. International Conference on Intelligent Systems for Molecular Biology},
  url          = {https://www.cs.princeton.edu/courses/archive/fall03/cs597F/Articles/biclustering_of_expression_data.pdf},
  urldate      = {2023-04-18},
  abstract     = {An efficient node-deletion algorithm is introduced to find submatrices in expression data that have low mean squared residue scores and it is shown to perform well in finding co-regulation patterns in yeast and human. An efficient node-deletion algorithm is introduced to find submatrices in expression data that have low mean squared residue scores and it is shown to perform well in finding co-regulation patterns in yeast and human. This introduces \&quot;biclustering\&quot;, or simultaneous clustering of both genes and conditions, to knowledge discovery from expression data. This approach overcomes some problems associated with traditional clustering methods, by allowing automatic discovery of similarity based on a subset of attributes, simultaneous clustering of genes and conditions, and overlapped grouping that provides a better representation for genes with multiple functions or regulated by many factors.},
  langid       = {english}
}
@article{chi2020ProvableConvexCoclustering,
  title        = {Provable {{Convex Co-Clustering}} of {{Tensors}}},
  author       = {Chi, Eric C and Gaines, Brian R and Sun, Will Wei and Zhou, Hua and Yang, Jian},
  date         = {2020},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume       = {21},
  number       = {1},
  pages        = {8792--8849},
  abstract     = {Cluster analysis is a fundamental tool for pattern discovery of complex heterogeneous data. Prevalent clustering methods mainly focus on vector or matrix-variate data and are not applicable to general-order tensors, which arise frequently in modern scientific and business applications. Moreover, there is a gap between statistical guarantees and computational efficiency for existing tensor clustering solutions due to the nature of their non-convex formulations. In this work, we bridge this gap by developing a provable convex formulation of tensor co-clustering. Our convex co-clustering (CoCo) estimator enjoys stability guarantees and its computational and storage costs are polynomial in the size of the data. We further establish a non-asymptotic error bound for the CoCo estimator, which reveals a surprising ``blessing of dimensionality'' phenomenon that does not exist in vector or matrix-variate cluster analysis. Our theoretical findings are supported by extensive simulated studies. Finally, we apply the CoCo estimator to the cluster analysis of advertisement click tensor data from a major online company. Our clustering results provide meaningful business insights to improve advertising effectiveness.},
  langid       = {english}
}
@inproceedings{daruru2009PervasiveParallelismData,
  title      = {Pervasive Parallelism in Data Mining: Dataflow Solution to Co-Clustering Large and Sparse {{Netflix}} Data},
  shorttitle = {Pervasive Parallelism in Data Mining},
  booktitle  = {Proceedings of the 15th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author     = {Daruru, Srivatsava and Marin, Nena M. and Walker, Matt and Ghosh, Joydeep},
  date       = {2009-06-28},
  series     = {{{KDD}} '09},
  pages      = {1115--1124},
  publisher  = {{Association for Computing Machinery}},
  location   = {{New York, NY, USA}},
  doi        = {10.1145/1557019.1557140},
  abstract   = {All Netflix Prize algorithms proposed so far are prohibitively costly for large-scale production systems. In this paper, we describe an efficient dataflow implementation of a collaborative filtering (CF) solution to the Netflix Prize problem [1] based on weighted coclustering [5]. The dataflow library we use facilitates the development of sophisticated parallel programs designed to fully utilize commodity multicore hardware, while hiding traditional difficulties such as queuing, threading, memory management, and deadlocks.迄今为止提出的所有 Netflix Prize 算法对于大规模生产系统来说成本都高得令人望而却步。在本文中，我们描述了基于加权共聚 [5] 的 Netflix Prize 问题 [1] 协同过滤 (CF) 解决方案的高效数据流实现。我们使用的数据流库有助于开发旨在充分利用商用多核硬件的复杂并行程序，同时隐藏排队、线程、内存管理和死锁等传统困难。 The dataflow CF implementation first compresses the large, sparse training dataset into co-clusters. Then it generates recommendations by combining the average ratings of the co-clusters with the biases of the users and movies. When configured to identify 20x20 co-clusters in the Netflix training dataset, the implementation predicted over 100 million ratings in 16.31 minutes and achieved an RMSE of 0.88846 without any fine-tuning or domain knowledge. This is an effective real-time prediction runtime of 9.7 us per rating which is far superior to previously reported results. Moreover, the implemented co-clustering framework supports a wide variety of other large-scale data mining applications and forms the basis for predictive modeling on large, dyadic datasets [4, 7].数据流 CF 实现首先将大型稀疏训练数据集压缩为联合集群。然后，它通过将共同集群的平均评分与用户和电影的偏见相结合来生成推荐。当配置为识别 Netflix 训练数据集中的 20x20 联合集群时，该实施在 16.31 分钟内预测了超过 1 亿个评级，并且在没有任何微调或领域知识的情况下实现了 0.88846 的 RMSE。这是每次评级 9.7 us 的有效实时预测运行时间，远优于之前报告的结果。此外，已实施的联合聚类框架支持各种其他大规模数据挖掘应用程序，并构成了对大型二元数据集进行预测建模的基础 [4、7]。},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn       = {978-1-60558-495-9},
  langid     = {english}
}
@inproceedings{dhillon2001CoclusteringDocumentsWords,
  title      = {Co-Clustering Documents and Words Using Bipartite Spectral Graph Partitioning},
  booktitle  = {Proceedings of the Seventh {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author     = {Dhillon, Inderjit S.},
  date       = {2001-08-26},
  pages      = {269--274},
  publisher  = {{ACM}},
  location   = {{San Francisco California}},
  doi        = {10.1145/502512.502550},
  url        = {https://dl.acm.org/doi/10.1145/502512.502550},
  urldate    = {2024-02-08},
  abstract   = {Bothdoumentlusteringandwordlusteringarewellstudiedproblems.Mostexistingalgorithmslusterdouments andwordsseparatelybutnotsimultaneously.Inthispaper wepresentthenovelideaofmodelingthedoumentolletionasabipartitegraphbetweendoumentsandwords,usingwhihthesimultaneouslusteringproblemanbeposed asabipartitegraphpartitioningproblem.Tosolvethepartitioningproblem,weuseanewspetralo-lusteringalgorithmthatusestheseondleftandrightsingularvetorsof anappropriatelysaledword-doumentmatrixtoyieldgood bipartitionings.Thespetralalgorithmenjoyssomeoptimalityproperties;itanbeshownthatthesingularvetors solvearealrelaxationtotheNP-ompletegraphbipartitioningproblem.Wepresentexperimentalresultstoverifythat theresultingo-lusteringalgorithmworkswellinpratie.},
  eventtitle = {{{KDD01}}: {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn       = {978-1-58113-391-2},
  langid     = {english},
  keywords   = {/unread,good cocluster},
  file       = {D\:\\zihan\\Zotero\\storage\\VIX9F4QT\\Dhillon - 2001 - Co-clustering documents and words using bipartite .pdf;D\:\\zihan\\Zotero\\storage\\Z6QS73SY\\Dhillon - 2001 - Co-clustering documents and words using bipartite spectral graph partitioning.pdf}
}@inproceedings{dhillon2003InformationtheoreticCoclustering,
  title      = {Information-Theoretic Co-Clustering},
  booktitle  = {Proceedings of the Ninth {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining  - {{KDD}} '03},
  author     = {Dhillon, Inderjit S. and Mallela, Subramanyam and Modha, Dharmendra S.},
  date       = {2003-08-24},
  series     = {{{KDD}} '03},
  pages      = {89--98},
  publisher  = {{Association for Computing Machinery}},
  location   = {{New York, NY, USA}},
  doi        = {10.1145/956750.956764},
  abstract   = {Two-dimensional contingency or co-occurrence tables arise frequently in important applications such as text, web-log and market-basket data analysis. A basic problem in contingency table analysis is co-clustering: simultaneous clustering of the rows and columns. A novel theoretical formulation views the contingency table as an empirical joint probability distribution of two discrete random variables and poses the co-clustering problem as an optimization problem in information theory---the optimal co-clustering maximizes the mutual information between the clustered random variables subject to constraints on the number of row and column clusters. We present an innovative co-clustering algorithm that monotonically increases the preserved mutual information by intertwining both the row and column clusterings at all stages. Using the practical example of simultaneous word-document clustering, we demonstrate that our algorithm works well in practice, especially in the presence of sparsity and high-dimensionality.},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn       = {978-1-58113-737-8},
  langid     = {english}
}
@inproceedings{ding2006OrthogonalNonnegativeMatrix,
  title      = {Orthogonal Nonnegative Matrix T-Factorizations for Clustering},
  booktitle  = {Proceedings of the 12th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author     = {Ding, Chris and Li, Tao and Peng, Wei and Park, Haesun},
  date       = {2006-08-20},
  series     = {{{KDD}} '06},
  pages      = {126--135},
  publisher  = {{Association for Computing Machinery}},
  location   = {{New York, NY, USA}},
  doi        = {10.1145/1150402.1150420},
  abstract   = {Currently, most research on nonnegative matrix factorization (NMF)focus on 2-factor \$X=FG\^T\$ factorization. We provide a systematicanalysis of 3-factor \$X=FSG\^T\$ NMF. While it unconstrained 3-factor NMF is equivalent to it unconstrained 2-factor NMF, itconstrained 3-factor NMF brings new features to it constrained 2-factor NMF. We study the orthogonality constraint because it leadsto rigorous clustering interpretation. We provide new rules for updating \$F,S, G\$ and prove the convergenceof these algorithms. Experiments on 5 datasets and a real world casestudy are performed to show the capability of bi-orthogonal 3-factorNMF on simultaneously clustering rows and columns of the input datamatrix. We provide a new approach of evaluating the quality ofclustering on words using class aggregate distribution andmulti-peak distribution. We also provide an overview of various NMF extensions andexamine their relationships.目前，大多数关于非负矩阵分解（NMF）的研究都集中在2-factor \$X=FG\^T\$ factorization上。我们提供了 3 因子 \$X=FSG\^T\$ NMF 的系统分析。虽然无约束 3 因子 NMF 等同于无约束 2 因子 NMF，但有约束 3 因子 NMF 为其有约束 2 因子 NMF 带来了新特征。我们研究正交性约束，因为它会导致严格的聚类解释。我们提供了更新\$F、S、G\$的新规则，并证明了这些算法的收敛性。对 5 个数据集和真实世界的案例研究进行了实验，以显示双正交 3 因子 NMF 在同时聚类输入数据矩阵的行和列上的能力。我们提供了一种使用类聚合分布和多峰分布来评估词聚类质量的新方法。我们还提供了各种 NMF 扩展的概述并检查了它们的关系。},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn       = {978-1-59593-339-3},
  langid     = {english}
}

@inproceedings{dongkuanxu2019DeepCoClustering,
  title        = {Deep co-clustering},
  author       = {Xu, Dongkuan and Cheng, Wei and Zong, Bo and Ni, Jingchao and Song, Dongjin and Yu, Wenchao and Chen, Yuncong and Chen, Haifeng and Zhang, Xiang},
  booktitle    = {Proceedings of the 2019 SIAM International Conference on Data Mining},
  pages        = {414--422},
  year         = {2019},
  organization = {SIAM}
}

@article{junweihan2017BilateralKMeansAlgorithm,
  title    = {Bilateral K-{{Means Algorithm}} for {{Fast Co-Clustering}}},
  author   = {{Junwei Han} and {Kun Song} and {Feiping Nie} and {Xuelong Li}},
  date     = {2017},
  abstract = {With the development of the information technology, the amount of data, e.g. text, image and video, has been increased rapidly. Efficiently clustering those large scale data sets is a challenge. To address this problem, this paper proposes a novel co-clustering method named bilateral k-means algorithm (BKM) for fast co-clustering. Different from traditional k-means algorithms, the proposed method has two indicator matrices P and Q and a diagonal matrix S to be solved, which represent the cluster memberships of samples and features, and the co-cluster centres, respectively. Therefore, it could implement different clustering tasks on the samples and features simultaneously. We also introduce an effective approach to solve the proposed method, which involves less multiplication. The computational complexity is analyzed. Extensive experiments on various types of data sets are conducted. Compared with the state-of-the-art clustering methods, the proposed BKM not only has faster computational speed, but also achieves promising clustering results.}
}
@inproceedings{keshet2016prediction,
  title        = {Prediction-Based, Prioritized Market-Share Insight Extraction},
  author       = {Keshet, Renato and Maor, Alina and Kour, George},
  booktitle    = {Advanced Data Mining and Applications: 12th International Conference, ADMA 2016, Gold Coast, QLD, Australia, December 12-15, 2016, Proceedings 12},
  pages        = {81--94},
  year         = {2016},
  organization = {Springer}
}
@article{khan2020CoClusteringRevealSalient,
  title        = {Co-{{Clustering}} to {{Reveal Salient Facial Features}} for {{Expression Recognition}}},
  author       = {Khan, Sheheryar and Chen, Lijiang and Yan, Hong},
  date         = {2020-04-01},
  journaltitle = {IEEE Transactions on Affective Computing},
  shortjournal = {IEEE Trans. Affective Comput.},
  volume       = {11},
  number       = {2},
  pages        = {348--360},
  issn         = {1949-3045, 2371-9850},
  doi          = {10.1109/TAFFC.2017.2780838},
  abstract     = {Facial expressions are a strong visual intimation of gestural behaviors. The intelligent ability to learn these non-verbal cues of the humans is the key characteristic to develop efficient human computer interaction systems. Extracting an effective representation from facial expression images is a crucial step that impacts the recognition accuracy. In this paper, we propose a novel feature selection strategy using singular value decomposition (SVD) based co-clustering to search for the most salient regions in terms of facial features that possess a high discriminating ability among all expressions. To the best of our knowledge, this is the first known attempt to explicitly perform co-clustering in the facial expression recognition domain. In our method, Gabor filters are used to extract local features from an image and then discriminant features are selected based on the class membership in co-clusters. Experiments demonstrate that co-clustering localizes the salient regions of the face image. Not only does the procedure reduce the dimensionality but also improves the recognition accuracy. Experiments on CK plus, JAFFE and MMI databases validate the existence and effectiveness of these learned facial features.},
  eventtitle   = {{{IEEE Transactions}} on {{Affective Computing}}},
  langid       = {english}
}

@article{kim2022ABCAttributedBipartite,
  title        = {{{ABC}}: {{Attributed}} Bipartite Co-Clustering},
  shorttitle   = {{{ABC}}},
  author       = {Kim, Junghoon and Feng, Kaiyu and Cong, Gao and Zhu, Diwen and Yu, Wenyuan and Miao, Chunyan},
  date         = {2022-06-01},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proceedings of the VLDB Endowment},
  volume       = {15},
  number       = {10},
  pages        = {2134--2147},
  issn         = {2150-8097},
  doi          = {10.14778/3547305.3547318},
  abstract     = {Finding a set of co-clusters in a bipartite network is a fundamental and important problem. In this paper, we present the Attributed Bipartite Co-clustering (ABC) problem which unifies two main concepts: (i) bipartite modularity optimization, and (ii) attribute cohesiveness. To the best of our knowledge, this is the first work to find co-clusters while considering the attribute cohesiveness. We prove that ABC is NP-hard and is not in APX, unless P=NP. We propose three algorithms: (1) a top-down algorithm; (2) a bottom-up algorithm; (3) a group matching algorithm. Extensive experimental results on real-world attributed bipartite networks demonstrate the efficiency and effectiveness of our algorithms.}
}
@article{kluger2003SpectralBiclusteringMicroarray,
  title        = {Spectral {{Biclustering}} of {{Microarray Data}}: {{Coclustering Genes}} and {{Conditions}}},
  shorttitle   = {Spectral {{Biclustering}} of {{Microarray Data}}},
  author       = {Kluger, Yuval and Basri, Ronen and Chang, Joseph T. and Gerstein, Mark},
  date         = {2003-04-01},
  journaltitle = {Genome Research},
  shortjournal = {Genome Res.},
  volume       = {13},
  number       = {4},
  eprint       = {12671006},
  eprinttype   = {pmid},
  pages        = {703--716},
  publisher    = {{Cold Spring Harbor Lab}},
  issn         = {1088-9051, 1549-5469},
  doi          = {10.1101/gr.648603},
  abstract     = {Global analyses of RNA expression levels are useful for classifying genes and overall phenotypes. Often these classification problems are linked, and one wants to find ``marker genes'' that are differentially expressed in particular sets of ``conditions.'' We have developed a method that simultaneously clusters genes and conditions, finding distinctive ``checkerboard'' patterns in matrices of gene expression data, if they exist. In a cancer context, these checkerboards correspond to genes that are markedly up- or downregulated in patients with particular types of tumors. Our method, spectral biclustering, is based on the observation that checkerboard structures in matrices of expression data can be found in eigenvectors corresponding to characteristic expression patterns across genes or conditions. In addition, these eigenvectors can be readily identified by commonly used linear algebra approaches, in particular the singular value decomposition (SVD), coupled with closely integrated normalization steps. We present a number of variants of the approach, depending on whether the normalization over genes and conditions is done independently or in a coupled fashion. We then apply spectral biclustering to a selection of publicly available cancer expression data sets, and examine the degree to which the approach is able to identify checkerboard structures. Furthermore, we compare the performance of our biclustering methods against a number of reasonable benchmarks (e.g., direct application of SVD or normalized cuts to raw data).},
  langid       = {english}
}
@article{lin2019OverviewCoClusteringMatrix,
  title        = {An Overview of Co-Clustering via Matrix Factorization},
  author       = {Lin, Renjie and Wang, Shiping and Guo, Wenzhong},
  date         = {2019},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume       = {7},
  pages        = {33481--33493},
  issn         = {2169-3536},
  doi          = {10.1109/ACCESS.2019.2904314},
  abstract     = {Co-clustering algorithms have been widely used for text clustering and gene expression through matrix factorization. In recent years, diverse co-clustering algorithms which group data points and features synchronously have shown their advantages over traditional one-side clustering. In order to solve the co-clustering problems, most existing methods relaxed constraints via matrix factorization. In this paper, we provide a detailed understanding of six co-clustering algorithms with different performance and robustness. We conduct comprehensive experiments in eight real-world datasets to compare and evaluate these co-clustering methods based on four evaluation metrics including clustering accuracy, normalized mutual information, adjusted rand index, and purity. Our findings demonstrate the strengths and weaknesses of these methods and provide insights to motivate further exploration of co-clustering methods and matrix factorization.},
  eventtitle   = {{{IEEE Access}}}
}
@article{madeira2004BiclusteringAlgorithmsBiological,
  title        = {Biclustering Algorithms for Biological Data Analysis: {{A}} Survey},
  author       = {Madeira, Sara C. and Oliveira, Arlindo L.},
  date         = {2004},
  journaltitle = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  shortjournal = {IEEE/acm Trans. Comput. Biol. Bioinformatics},
  eprint       = {17048406},
  eprinttype   = {pmid},
  doi          = {10.1109/tcbb.2004.2},
  abstract     = {A large number of clustering approaches have been proposed for the analysis of gene expression data obtained from microarray experiments. However, the results from the application of standard clustering methods to genes are limited. This limitation is imposed by the existence of a number of experimental conditions where the activity of genes is uncorrelated. A similar limitation exists when clustering of conditions is performed. For this reason, a number of algorithms that perform simultaneous clustering on the row and column dimensions of the data matrix has been proposed. The goal is to find submatrices, that is, subgroups of genes and subgroups of conditions, where the genes exhibit highly correlated activities for every condition. In this paper, we refer to this class of algorithms as biclustering. Biclustering is also referred in the literature as coclustering and direct clustering, among others names, and has also been used in fields such as information retrieval and data mining. In this comprehensive survey, we analyze a large number of existing approaches to biclustering, and classify them in accordance with the type of biclusters they can find, the patterns of biclusters that are discovered, the methods used to perform the search, the approaches used to evaluate the solution, and the target applications.},
  mag_id       = {2144544802},
  pmcid        = {null}
}
@inproceedings{siklosi2012ContentbasedTrustBias,
  title      = {Content-Based Trust and Bias Classification via Biclustering},
  booktitle  = {Proceedings of the 2nd {{Joint WICOW}}/{{AIRWeb Workshop}} on {{Web Quality}}},
  author     = {Sikl\'osi, D\'avid and Dar\'oczy, B\'alint and Bencz\'ur, Andr\'as A.},
  date       = {2012-04-16},
  series     = {{{WebQuality}} '12},
  pages      = {41--47},
  publisher  = {{Association for Computing Machinery}},
  location   = {{New York, NY, USA}},
  doi        = {10.1145/2184305.2184314},
  abstract   = {In this paper we improve trust, bias and factuality classification over Web data on the domain level. Unlike the majority of literature in this area that aims at extracting opinion and handling short text on the micro level, we aim to aid a researcher or an archivist in obtaining a large collection that, on the high level, originates from unbiased and trustworthy sources. Our method generates features as Jensen-Shannon distances from centers in a host-term biclustering. On top of the distance features, we apply kernel methods and also combine with baseline text classifiers. We test our method on the ECML/PKDD Discovery Challenge data set DC2010. Our method improves over the best achieved text classification NDCG results by over 3--10\% for neutrality, bias and trustworthiness. The fact that the ECML/PKDD Discovery Challenge 2010 participants reached an AUC only slightly above 0.5 indicates the hardness of the task.在本文中，我们在域级别上改进了对 Web 数据的信任、偏见和事实分类。与该领域的大多数旨在从微观层面提取意见\hspace{0pt}\hspace{0pt}和处理短文本的文献不同，我们的目标是帮助研究人员或档案管理员获得大量收藏，这些收藏在高层次上来自公正和可信赖的来源。我们的方法生成的特征是 Jensen-Shannon 与主项双聚类中心的距离。在距离特征之上，我们应用内核方法并结合基线文本分类器。我们在 ECML/PKDD 发现挑战数据集 DC2010 上测试了我们的方法。我们的方法在中立性、偏见和可信度方面比最佳实现的文本分类 NDCG 结果提高了 3--10\% 以上。事实上，2010 年 ECML/PKDD 发现挑战赛参与者达到的 AUC 仅略高于 0.5，这表明任务的难度。},
  eventtitle = {Joint {{WICOW}}/{{AIRWeb Workshop}} on {{Web Quality}}},
  isbn       = {978-1-4503-1237-0},
  langid     = {english}
}
@article{song2013ConstrainedTextCoclustering,
  author   = {Song, Yangqiu and Pan, Shimei and Liu, Shixia and Wei, Furu and Zhou, Michelle X. and Qian, Weihong},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Constrained Text Coclustering with Supervised and Unsupervised Constraints},
  year     = {2013},
  volume   = {25},
  number   = {6},
  pages    = {1227-1239},
  abstract = {In this paper, we propose a novel constrained coclustering method to achieve two goals. First, we combine information-theoretic coclustering and constrained clustering to improve clustering performance. Second, we adopt both supervised and unsupervised constraints to demonstrate the effectiveness of our algorithm. The unsupervised constraints are automatically derived from existing knowledge sources, thus saving the effort and cost of using manually labeled constraints. To achieve our first goal, we develop a two-sided hidden Markov random field (HMRF) model to represent both document and word constraints. We then use an alternating expectation maximization (EM) algorithm to optimize the model. We also propose two novel methods to automatically construct and incorporate document and word constraints to support unsupervised constrained clustering: 1) automatically construct document constraints based on overlapping named entities (NE) extracted by an NE extractor; 2) automatically construct word constraints based on their semantic distance inferred from WordNet. The results of our evaluation over two benchmark data sets demonstrate the superiority of our approaches against a number of existing approaches.},
  keywords = {},
  doi      = {10.1109/TKDE.2012.45},
  issn     = {1558-2191},
  month    = {6}
}
@article{sun2014BiforceLargescaleBicluster,
  title        = {Bi-Force: {{Large-scale}} Bicluster Editing and Its Application to Gene Expression Data Biclustering},
  shorttitle   = {Bi-{{Force}}},
  author       = {Sun, Peng and Speicher, Nora K and R\"ottger, Richard and Guo, Jiong and Baumbach, Jan},
  date         = {2014-05-01},
  journaltitle = {Nucleic Acids Research},
  shortjournal = {Nucleic Acids Res.},
  volume       = {42},
  number       = {9},
  pages        = {e78-e78},
  issn         = {0305-1048, 1362-4962},
  doi          = {10.1093/nar/gku201},
  langid       = {english}
}
@article{vonluxburg2007TutorialSpectralClustering,
  title        = {A Tutorial on Spectral Clustering},
  author       = {family=Luxburg, given=Ulrike, prefix=von, useprefix=true},
  date         = {2007-12-01},
  journaltitle = {Statistics and Computing},
  shortjournal = {Stat. Comput.},
  volume       = {17},
  number       = {4},
  pages        = {395--416},
  issn         = {1573-1375},
  doi          = {10.1007/s11222-007-9033-z},
  url          = {https://doi.org/10.1007/s11222-007-9033-z},
  urldate      = {2024-02-08},
  abstract     = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
  langid       = {english},
  keywords     = {Graph Laplacian,Spectral clustering},
  file         = {D:\zihan\Zotero\storage\R4CIW2ME\von Luxburg - 2007 - A tutorial on spectral clustering.pdf}
}
@article{wang2019DualHypergraphRegularized,
  title        = {Dual {{Hypergraph Regularized PCA}} for {{Biclustering}} of {{Tumor Gene Expression Data}}},
  author       = {Wang, Xuesong and Liu, Jian and Cheng, Yuhu and Liu, Aiping and Chen, Enhong},
  date         = {2019-12-01},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume       = {31},
  number       = {12},
  pages        = {2292--2303},
  issn         = {1041-4347, 1558-2191, 2326-3865},
  doi          = {10.1109/TKDE.2018.2874881},
  abstract     = {Clustering is a powerful approach to analyze gene expression data which is crucial to the investigation of effective treatment of cancer. Many graph regularize-based clustering methods have been proposed and shown to be superior to the traditional clustering methods. However, they only focus on the inner structure in samples and fail to take the feature manifold into account. In gene expression data, it's practical to hypothesize that both the samples and the genes lie on nonlinear low dimensional manifolds, namely sample manifold and gene manifold, respectively. Therefore in this paper, incorporating the geometric structures in both samples and features, we propose a Dual Hypergraph Regularized PCA (DHPCA) method for biclustering of tumor data. First, for gene expression data, we construct two hypergraphs, i.e., sample hypergraph and gene hypergraph, to estimate the intrinsic geometric structures of samples and genes. Then, we introduce the hypergraph regularization on both gene side and sample side. Finally, our biclustering method is formulated as two hypergraph regularized PCA with closed-form solution. We experimentally validate our proposed DHPCA algorithm on real applications and the promising results indicate its potential in high dimension data analysis.},
  eventtitle   = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  langid       = {english}
}
@article{yan2017CoclusteringMultidimensionalBig,
  title        = {Coclustering of {{Multidimensional Big Data}}: {{A Useful Tool}} for {{Genomic}}, {{Financial}}, and {{Other Data Analysis}}},
  author       = {Yan, Hong},
  date         = {2017-04},
  journaltitle = {IEEE Systems, Man, and Cybernetics Magazine},
  shortjournal = {IEEE Syst. Man Cybern. Mag.},
  volume       = {3},
  number       = {2},
  pages        = {23--30},
  publisher    = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  issn         = {2333-942X, 2380-1298},
  doi          = {10.1109/msmc.2017.2664218},
  abstract     = {The analysis of a multidimensional data array is necessary in many applications. Although a data set can be very large, it is possible that meaningful and coherent patterns embedded in the data array are much smaller in size. For example, in genomic data, we may want to find a subset of genes that coexpress under a subset of conditions. In this article, I will explain coclustering algorithms for solving the coherent pattern-detection problem. In these methods, a coherent pattern corresponds to a low-rank matrix or tensor and can be represented as an intersection of hyperplanes in a high-dimensional space. We can then extract coherent patterns from the large data array by detecting hyperplanes. Examples will be provided to demonstrate the effectiveness of the coclustering algorithms for solving unsupervised pattern classification problems.},
  langid       = {english}
}
@article{lloyd1982LeastSquaresQuantization,
  title = {Least squares quantization in PCM},
  author = {Lloyd, S.},
  date = {1982-03},
  journaltitle = {IEEE Transactions on Information Theory},
  shortjournal = {IEEE Trans. Inf. Theory},
  volume = {28},
  number = {2},
  pages = {129--137},
  issn = {1557-9654},
  doi = {10.1109/TIT.1982.1056489},
  url = {https://ieeexplore.ieee.org/abstract/document/1056489?casa_token=kwi9HKhZpa4AAAAA:XAz-8p-AnmEMY7QTsU6zifNgg9FlV6r0P9lyerWMwFcXGL7KI9Q0L3sILu4fFYupB0_clS_KmRU},
  urldate = {2024-02-09},
  abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for2\^bquanta,b=1,2, \textbackslash cdots, 7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.},
  eventtitle = {IEEE Transactions on Information Theory},
  langid = {latin},
  file = {D:\zihan\Zotero\storage\9KQS869D\1056489.html}
}

@incollection{macqueen1967MethodsClassificationAnalysis,
  title = {Some Methods for Classification and Analysis of Multivariate Observations},
  booktitle = {Proceedings of the {{Fifth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}, {{Volume}} 1: {{Statistics}}},
  author = {MacQueen, J.},
  date = {1967-01-01},
  volume = {5.1},
  pages = {281--298},
  publisher = {{University of California Press}},
  url = {https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Some-methods-for-classification-and-analysis-of-multivariate-observations/bsmsp/1200512992},
  urldate = {2024-02-09},
  langid = {english},
  file = {D:\zihan\Zotero\storage\G68JERKL\MacQueen - 1967 - Some methods for classification and analysis of multivariate observations.pdf}
}
@article{dempster1977MaximumLikelihoodIncomplete,
  title = {Maximum Likelihood from Incomplete Data via the {{EM}} Algorithm},
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  date = {1977},
  journaltitle = {Journal of The Royal Statistical Society Series B-methodological},
  shortjournal = {J. Roy. Stat. Soc. B. Met.},
  volume = {39},
  number = {1},
  pages = {1--22},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1977.tb01600.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1977.tb01600.x},
  urldate = {2024-02-09},
  abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
  langid = {english},
  keywords = {em algorithm,incomplete data,maximum likelihood,posterior mode},
  file = {D:\zihan\Zotero\storage\XRZKRJTD\j.2517-6161.1977.tb01600.html}
}
@article{chen2023FastFlexibleBipartite,
  title = {Fast Flexible Bipartite Graph Model for Co-Clustering},
  author = {Chen, Wei and Wang, Hongjun and Long, Zhiguo and Li, Tianrui},
  date = {2023-07},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {35},
  number = {7},
  pages = {6930--6940},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2022.3194275},
  url = {https://ieeexplore.ieee.org/abstract/document/9842309?casa_token=tBB7EWbNjl4AAAAA:z8a3lmH148KS9o-mrsGLjkehMkg21P3uHIyXV8rFwQ4JnorgURG1W7LUMPuNEr6dyxOZ_eG8RTg},
  urldate = {2024-02-09},
  abstract = {Co-clustering methods make use of the correlation between samples and attributes to explore the co-occurrence structure in data. These methods have played a significant role in gene expression analysis, image segmentation, and document clustering. In bipartite graph partition-based co-clustering methods, the relationship between samples and attributes is described by constructing a diagonal symmetric bipartite graph matrix, which is clustered by the philosophy of spectral clustering. However, this not only has high time complexity but also the same number of row and column clusters. In fact, the number of categories of rows and columns often changes in the real world. To address these problems, this paper proposes a novel fast flexible bipartite graph model for the co-clustering method (FBGPC) that directly uses the original matrix to construct the bipartite graph. Then, it uses the inflation operation to partition the bipartite graph in order to learn the co-occurrence structure of the original data matrix based on the inherent relationship between bipartite graph partitioning and co-clustering. Finally, hierarchical clustering is used to obtain the clustering results according to the set relationship of the co-occurrence structure. Extensive empirical results show the effectiveness of our proposed model and verify the faster performance, generality, and flexibility of our model.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  langid = {english},
  keywords = {Bipartite graph,bipartite graph partition,Clustering algorithms,Clustering methods,Co-clustering,Computational modeling,Data models,faster performance,flexibility,Partitioning algorithms,Time complexity},
  file = {D\:\\zihan\\Zotero\\storage\\IQIEQB6I\\Chen 等 - 2023 - Fast flexible bipartite graph model for co-clustering.pdf;D\:\\zihan\\Zotero\\storage\\KED2JCCS\\9842309.html}
}

@inproceedings{kumar2023CoclusteringBasedMethods,
  title = {Co-Clustering Based Methods and Their Significance for Recommender Systems},
  author = {Kumar, Naresh and Sheeba, Merlin},
  editor = {Morusupalli, Raghava and Dandibhotla, Teja Santosh and Atluri, Vani Vathsala and Windridge, David and Lingras, Pawan and Komati, Venkateswara Rao},
  date = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {14078},
  pages = {513--522},
  publisher = {{Springer Nature Switzerland}},
  location = {{Cham}},
  doi = {10.1007/978-3-031-36402-0_48},
  url = {https://link.springer.com/10.1007/978-3-031-36402-0_48},
  abstract = {In the contemporary era, businesses are driven by Internet based web or mobile applications. In every conceivable area of research, it is indispensable for such applications to have a recommender system to expedite the interactions between customers and business entity for faster convergence. Provided this fact, there is need for leveraging such systems as they have unprecedented impact on businesses across the globe. In this regard, identification of merits and demerits in the existing methods used to realize recommender systems is to be given paramount importance. In this paper, we review literature to ascertain useful facts pertaining to different approaches to make recommender systems. Since recommender systems lubricate the process of commercial or otherwise interactions with consumers, for business entities it is imperative to have applications with built-in recommender system. The literature review made in this paper provides different aspects of recommender systems such as datasets, methods and their utility in the current business scenarios. It throws light into the research gaps that help in further research and improvement based on novel data mining approaches.},
  isbn = {978-3-031-36402-0},
  langid = {english},
  keywords = {/unread,co-clustering 协同聚类,collaborative filtering methods
协同过滤方法,content based filtering methods
基于内容的过滤方法,recommendation system},
  file = {D:\zihan\Zotero\storage\4UE7FRTS\Kumar and Sheeba - 2023 - Co-clustering Based Methods and Their Significance for Recommender Systems.pdf}
}

@article{zhao2023MultiviewCoclusteringMultisimilarity,
  title = {Multi-View Co-Clustering with Multi-Similarity},
  author = {Zhao, Ling and Ma, Yunpeng and Chen, Shanxiong and Zhou, Jun},
  date = {2023-07-01},
  journaltitle = {Applied Intelligence},
  shortjournal = {Appl. Intell.},
  volume = {53},
  number = {13},
  pages = {16961--16972},
  issn = {1573-7497},
  doi = {10.1007/s10489-022-04385-4},
  url = {https://doi.org/10.1007/s10489-022-04385-4},
  urldate = {2023-12-11},
  abstract = {Multi-view co-clustering, which clustering the two dimensions of samples and features of multi-view data at the same time, has attracted much attention in recent years. It aims to exploit the duality of multi-view data to get better clustering results. However, most of the existing multi-view co-clustering algorithms consider the sample-feature information of the data while ignoring the sample-sample, feature-feature information, and thus cannot fully mine the potential information contained in the data. Therefore, this paper proposes a multi-view co-clustering based on multi-similarity. In particular, based on spectral clustering, we propose a method of constructing graph to improve the performance of clustering, which is no longer limited to the relevance between samples and features. At the same time, inspired by the ensemble algorithm, we use multiple co-clustering algorithms to calculate the similarity information of each view data, which makes the algorithm more robust. Compared with the existing multi-view co-clustering methods, the proposed algorithm exploits the more comprehensive similarity information in each view data, including sample-sample, feature-feature, and sample-feature similarity information. We performed experiments on several benchmark datasets. Due to mining and using more similarity information, our experimental results are better than the comparison method in the three evaluation indicators. In particular, on some data with co-occurrence features such as (word-document), our algorithm achieves better results and can obtain higher accuracy.},
  langid = {english},
  keywords = {/unread,Co-clustering,Ensemble,Multi-view clustering,Similarity},
  annotation = {影响因子: 5.3 CCF: C 5年影响因子: 5.2},
  file = {D:\zihan\Zotero\storage\TJXWYC8K\Zhao et al. - 2023 - Multi-view co-clustering with multi-similarity.pdf}
}
@article{wu2023EffectiveClusteringStructured,
  title = {Effective Clustering via Structured Graph Learning},
  author = {Wu, Danyang and Nie, Feiping and Lu, Jitao and Wang, Rong and Li, Xuelong},
  date = {2023-08},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {35},
  number = {8},
  pages = {7909--7920},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2022.3222411},
  url = {https://ieeexplore.ieee.org/abstract/document/9950731?casa_token=l2kiAyfTkRwAAAAA:AuM_jHYA3hOo4aAOU-6OPj0RsYeyW5TdCM5wGn7XISn5AuoVja6moGdhUdx66jNocR6Q3_BMO5s},
  urldate = {2024-02-09},
  abstract = {Given an affinity graph of data samples, graph-based clustering aims to partition these samples into disjoint groups based on the affinities, and most previous works are based on spectral clustering. However, two problems among spectral-based methods heavily affect the clustering performance. First, the randomness of post-processing procedures, such as KK-means, affects the stability of clustering. Second, the separated stages of spectral-based methods, including graph construction, spectral embedding learning, and clustering decision, lead to mismatched problems. In this paper, we explore a structured graph learning (SGL) framework that aims to fuse these stages to improve clustering stability. Specifically, SGL adaptively learns a structured affinity graph that contains exact kk connected components. Each connected component corresponds to a cluster so clustering assignments can be directly obtained according to the connectivity of the learned graph. In this way, SGL avoids the randomness brought by reliance on traditional post-processing procedures. Meanwhile, the graph construction and structured graph learning procedures happen simultaneously, which alleviates the mismatched problem effectively. Moreover, we propose an efficient algorithm to solve the involved optimization problems and discuss the connections between this work and previous works. Numerical experiments on several synthetic and real datasets demonstrate the effectiveness of our methods.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  langid = {english},
  keywords = {adaptive neighbors,block diagonal similarity matrix,Clustering,Clustering algorithms,Clustering methods,Eigenvalues and eigenfunctions,Optimization,Partitioning algorithms,Stability analysis,structured graph learning,Task analysis},
  file = {D:\zihan\Zotero\storage\VETKFYQY\9950731.html}
}

@article{yuan2023JointNetworkTopology,
  title = {Joint Network Topology Inference via Structural Fusion Regularization},
  author = {Yuan, Yanli and Soh, De Wen and Guo, Kun and Xiong, Zehui and Quek, Tony Q. S.},
  date = {2023-10},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {35},
  number = {10},
  pages = {10351--10364},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2023.3264971},
  url = {https://ieeexplore.ieee.org/abstract/document/10093994?casa_token=iyl8ydQdtNEAAAAA:XAHX1NU0NYuwyDlW4WR9Is31rkCuKzEMhB7yCpsxpyTvv5J_Z7_cEUipgeQn7L0-PnjMVx9ZtlY},
  urldate = {2024-02-09},
  abstract = {Joint network topology inference represents a canonical problem of jointly learning multiple graph Laplacian matrices from heterogeneous graph signals. In such a problem, a widely employed assumption is that of a simple common component shared among multiple graphs. However, in practice, a more intricate topological pattern, comprising simultaneously of homogeneous and heterogeneous components, would exhibit in multiple graphs. In this paper, we propose a general graph estimator based on a novel structural fusion regularization that enables us to jointly learn multiple graphs with such complex topological patterns, and enjoys rigorous theoretical guarantees. Specifically, in the proposed regularization term, the structural similarity among graphs is characterized by a Gram matrix, which enables us to flexibly model different types of network structural similarities through different Gram matrix choices. Algorithmically, the regularization term, coupling the parameters together, makes the formulated optimization problem intractable, and thus, we develop an implementable algorithm based on the alternating direction method of multipliers (ADMM) to solve it. Theoretically, non-asymptotic statistical analysis is provided, which precisely characterizes the minimum sample size required for the consistency of the graph estimator. This analysis also provides high-probability bounds on the estimation error as a function of graph structural similarities and other key problem parameters. Finally, the superior performance of the proposed method is demonstrated through simulated and real data examples.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  langid = {english},
  keywords = {Correlation,Graph Laplacian,graph signals,Laplace equations,Network topology,network topology inference,non-asymptotic statistical analysis,regularization,Social networking (online),Statistical analysis,Task analysis,Topology},
  file = {D\:\\zihan\\Zotero\\storage\\RL32UYSL\\Yuan 等 - 2023 - Joint network topology inference via structural fusion regularization.pdf;D\:\\zihan\\Zotero\\storage\\34XLMT56\\10093994.html}
}

@article{zhang2023AdaptiveGraphConvolution,
  title = {Adaptive Graph Convolution Methods for Attributed Graph Clustering},
  author = {Zhang, Xiaotong and Liu, Han and Li, Qimai and Wu, Xiao-Ming and Zhang, Xianchao},
  date = {2023-12},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {35},
  number = {12},
  pages = {12384--12399},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2023.3278721},
  url = {https://ieeexplore.ieee.org/abstract/document/10130603?casa_token=9w0BFlpS3OIAAAAA:R3hJZ_ESjZ6nxT56IrrTC8T44sgQagqKkz-DerHrRaWdag45BkswpEgOi_c0fHvKPHMjKQ7JNrs},
  urldate = {2024-02-09},
  abstract = {Attributed graph clustering is a challenging task as it requires to jointly model graph structure and node attributes. Although recent advances in graph convolutional networks have shown the effectiveness of graph convolution in combining structural and content information, there is limited understanding of how to properly apply it for attributed graph clustering. Previous methods commonly use a fixed and low order graph convolution, which only aggregates information of few-hop neighbours and hence cannot fully capture the cluster structures of diverse graphs. In this paper, we first propose an adaptive graph convolution method (AGC) for attributed graph clustering, which exploits high-order graph convolutions to capture global cluster structures and adaptively selects an appropriate order kk via intra-cluster distance. While AGC can find a reasonable kk and avoid over-smoothing, it is not sensitive to the gradual decline of clustering performance as kk increases. To search for a better kk, we further propose an improved adaptive graph convolution method (IAGC) that not only observes the variation of intra-cluster distance, but also considers the inconsistencies of filtered features with graph structure and raw features, respectively. We establish the validity of our methods by theoretical analysis and extensive experiments on various benchmark datasets.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  langid = {english},
  keywords = {Adaptation models,Adaptive graph convolution,attributed graph clustering,Automatic generation control,Clustering methods,Convolution,Feature extraction,low-pass graph filter,Proteins,Social networking (online)},
  file = {D\:\\zihan\\Zotero\\storage\\IETDDZCP\\Zhang 等 - 2023 - Adaptive graph convolution methods for attributed graph clustering.pdf;D\:\\zihan\\Zotero\\storage\\T59D3IJ5\\10130603.html}
}
@article{golchev2015BiclusteringAnalysisGene,
  title = {Biclustering Analysis of Gene Expression Data Using Multi-Objective Evolutionary Algorithms},
  author = {Golchev, Maryam and Davarpanah, S. H. and Liew, Alan Wee-Chung},
  date = {2015},
  journaltitle = {2015 International Conference on Machine Learning and Cybernetics (ICMLC)},
  shortjournal = {2015 International Conference on Machine Learning and Cybernetics (ICMLC)},
  volume = {2},
  pages = {505--510},
  doi = {10.1109/ICMLC.2015.7340608},
  url = {https://www.semanticscholar.org/paper/eb6ff576bec9920a8e39f5b13c1814c76f804794},
  abstract = {Clustering is an unsupervised learning technique that groups data into clusters using the entire conditions. However, sometimes, data is similar only under a subset of conditions. Biclustering allows clustering of rows and columns of a dataset simultaneously. It extracts more accurate information from sparse datasets. In recent years, biclustering has found many useful applications in different fields and many biclustering algorithms have been proposed. Using both row and column information of data, biclustering requires the optimization of two conflicting objectives. In this study, a new multi-objective evolutionary biclustering framework using SPEA2 is proposed. A heuristic local search based on the gene and condition deletion and addition is added into SPEA2 and the best bicluster is selected using a new quantitative measure that considers both its coherence and size. The performance of our algorithm is evaluated using simulated and gene expression data and compared with several well-known biclustering methods. The experimental results demonstrate better performance with respect to the size and MSR of detected biclusters and significant enrichment of detected genes.},
  langid = {english},
  keywords = {/unread,⛔ No INSPIRE recid found},
  annotation = {2 citations (Crossref) [2023-04-27] EI: 是 南农核心: 无 南农高质量: 无},
  file = {D:\zihan\Zotero\storage\4T2KKGML\Golchev et al. - 2015 - Biclustering analysis of gene expression data usin.pdf}
}

@article{higham2007SpectralClusteringIts,
  title = {Spectral Clustering and Its Use in Bioinformatics},
  author = {Higham, Desmond J. and Kalna, Gabriela and Kibble, Milla},
  date = {2007-07-01},
  journaltitle = {Journal of Computational and Applied Mathematics},
  shortjournal = {J. Comput. Appl. Math.},
  series = {Special Issue Dedicated to {{Professor Shinnosuke Oharu}} on the Occasion of His 65th Birthday},
  volume = {204},
  number = {1},
  pages = {25--37},
  issn = {0377-0427},
  doi = {10.1016/j.cam.2006.04.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0377042706002366},
  urldate = {2024-02-09},
  abstract = {We formulate a discrete optimization problem that leads to a simple and informative derivation of a widely used class of spectral clustering algorithms. Regarding the algorithms as attempting to bi-partition a weighted graph with N vertices, our derivation indicates that they are inherently tuned to tolerate all partitions into two non-empty sets, independently of the cardinality of the two sets. This approach also helps to explain the difference in behaviour observed between methods based on the unnormalized and normalized graph Laplacian. We also give a direct explanation of why Laplacian eigenvectors beyond the Fiedler vector may contain fine-detail information of relevance to clustering. We show numerical results on synthetic data to support the analysis. Further, we provide examples where normalized and unnormalized spectral clustering is applied to microarray data—here the graph summarizes similarity of gene activity across different tissue samples, and accurate clustering of samples is a key task in bioinformatics.},
  langid = {english},
  keywords = {Balancing threshold,Fiedler vector,Gene expression,Graph Laplacian,Maximum likelihood,Microarray,Partitioning,Random graph,Rayleigh–Ritz Theorem,Scaling},
  file = {D\:\\zihan\\Zotero\\storage\\9CYFGIJN\\Higham 等 - 2007 - Spectral clustering and its use in bioinformatics.pdf;D\:\\zihan\\Zotero\\storage\\6WUE95ZK\\S0377042706002366.html}
}

@article{zhao2012BiclusteringAnalysisPattern,
  title = {Biclustering Analysis for Pattern Discovery: Current Techniques, Comparative Studies and Applications},
  shorttitle = {Biclustering {{Analysis}} for {{Pattern Discovery}}},
  author = {Zhao, Hongya and Wee-Chung Liew, Alan and Z. Wang, Doris and Yan, Hong},
  date = {2012-03-01},
  journaltitle = {Current Bioinformatics},
  shortjournal = {Curr. Bioinf.},
  volume = {7},
  number = {1},
  pages = {43--55},
  issn = {15748936},
  doi = {10.2174/157489312799304413},
  url = {http://www.eurekaselect.com/openurl/content.php?genre=article&issn=1574-8936&volume=7&issue=1&spage=43},
  urldate = {2022-09-29},
  langid = {english},
  keywords = {/unread,⛔ No INSPIRE recid found,yan cocluster},
  annotation = {31 citations (Crossref) [2022-10-21] JCR分区: Q1 中科院分区升级版: 生物学4区 影响因子: 4.85 5年影响因子: 3.111 JCI: 0.86 南农核心: 无 南农高质量: 无},
  file = {D:\zihan\Zotero\storage\62MPAKFA\Biclustering_Analysis_for_Pattern_Discovery_Zhao_et_al_2012.pdf}
}
@incollection{bouchareb2019ModelBasedCoclustering,
  title = {Model Based Co-Clustering of Mixed Numerical and Binary Data},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Management}}},
  author = {Bouchareb, Aichetou and Boullé, Marc and Clérot, Fabrice and Rossi, Fabrice},
  date = {2019},
  pages = {3--22},
  publisher = {{Springer, Cham}},
  issn = {1860-9503},
  doi = {10.1007/978-3-030-18129-1_1},
  url = {https://link.springer.com/chapter/10.1007/978-3-030-18129-1_1},
  urldate = {2024-02-09},
  abstract = {Co-clustering is a data mining technique used to extract the underlying block structureBouchareb, Aichetou\&\#160;between the rows and columns of a data matrix. Many approaches have been studied and have shown their capacity to extractBoull\&\#233;, Marc such structures...},
  isbn = {978-3-030-18129-1},
  langid = {english},
  file = {D:\zihan\Zotero\storage\B6BTC8D7\Bouchareb 等 - 2019 - Model based co-clustering of mixed numerical and binary data.pdf}
}

@article{busygin2008BiclusteringDataMining,
  title = {Biclustering in Data Mining},
  author = {Busygin, Stanislav and Prokopyev, Oleg and Pardalos, Panos M.},
  date = {2008-09},
  journaltitle = {Computers \& Operations Research},
  shortjournal = {Comput. Oper. Res.},
  series = {Part {{Special Issue}}: {{Bio-inspired Methods}} in {{Combinatorial Optimization}}},
  volume = {35},
  number = {9},
  pages = {2964--2987},
  issn = {03050548},
  doi = {10.1016/j.cor.2007.01.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0305054807000159},
  urldate = {2022-10-17},
  abstract = {Biclustering consists in simultaneous partitioning of the set of samples and the set of their attributes (features) into subsets (classes). Samples and features classified together are supposed to have a high relevance to each other. In this paper we review the most widely used and successful biclustering techniques and their related applications. This survey is written from a theoretical viewpoint emphasizing mathematical concepts that can be met in existing biclustering techniques.},
  langid = {english},
  keywords = {Biclustering,Classification,Clustering,Data mining,Survey,to follow},
  annotation = {171 citations (Crossref) [2022-10-21] JCR分区: Q1 中科院分区升级版: 工程技术2区 影响因子: 5.16 5年影响因子: 5.211 EI: 是 AJG: 3 FMS: B JCI: 0.99 南农核心: 无 南农高质量: 无},
  file = {D\:\\zihan\\Zotero\\storage\\P7W66SUZ\\Biclustering_in_data_mining_Busygin_et_al_2008.pdf;D\:\\zihan\\Zotero\\storage\\MGCVQUZP\\S0305054807000159.html}
}

@article{dhillon2007WeightedGraphCuts,
  title = {Weighted Graph Cuts without Eigenvectors a Multilevel Approach},
  author = {Dhillon, Inderjit S. and Guan, Yuqiang and Kulis, Brian},
  date = {2007-11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {29},
  number = {11},
  pages = {1944--1957},
  issn = {1939-3539},
  doi = {10.1109/TPAMI.2007.1115},
  url = {https://ieeexplore.ieee.org/abstract/document/4302760?casa_token=f1EZcr5W854AAAAA:q6s3QPMFTkKJE7IPzQcQ5PiiZjN-KZz44D4rQRzwGsVEOZ0IsF8Io-l4lUj0x2_NjUtTIBn9qGQ},
  urldate = {2024-02-08},
  abstract = {A variety of clustering algorithms have recently been proposed to handle data that is not linearly separable; spectral clustering and kernel k-means are two of the main methods. In this paper, we discuss an equivalence between the objective functions used in these seemingly different methods - in particular, a general weighted kernel k-means objective is mathematically equivalent to a weighted graph clustering objective. We exploit this equivalence to develop a fast high-quality multilevel algorithm that directly optimizes various weighted graph clustering objectives, such as the popular ratio cut, normalized cut, and ratio association criteria. This eliminates the need for any eigenvector computation for graph clustering problems, which can be prohibitive for very large graphs. Previous multilevel graph partitioning methods such as Metis have suffered from the restriction of equal-sized clusters; our multilevel algorithm removes this restriction by using kernel k-means to optimize weighted graph cuts. Experimental results show that our multilevel algorithm outperforms a state-of-the-art spectral clustering algorithm in terms of speed, memory usage, and quality. We demonstrate that our algorithm is applicable to large-scale clustering tasks such as image segmentation, social network analysis, and gene network analysis.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  langid = {english},
  keywords = {Algorithm design and analysis,Clustering,Clustering algorithms,Data mining,Data Mining,Graph Partitioning,Image analysis,Image segmentation,k-means,Kernel,Large-scale systems,Optimization methods,Partitioning algorithms,Segmentation,Social network services,Spectral Clustering},
  file = {D\:\\zihan\\Zotero\\storage\\JGZ4PCF7\\Dhillon 等 - 2007 - Weighted graph cuts without eigenvectors a multilevel approach.pdf;D\:\\zihan\\Zotero\\storage\\96LC4NSW\\4302760.html}
}

@article{wei2021HierarchicalHighorderCoclustering,
  title = {Hierarchical High-Order Co-Clustering Algorithm by Maximizing Modularity},
  author = {Wei, Jiahui and Ma, Huifang and Liu, Yuhang and Li, Zhixin and Li, Ning},
  date = {2021-10-01},
  journaltitle = {International Journal of Machine Learning and Cybernetics},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  volume = {12},
  number = {10},
  pages = {2887--2898},
  issn = {1868-808X},
  doi = {10.1007/s13042-021-01375-9},
  url = {https://doi.org/10.1007/s13042-021-01375-9},
  urldate = {2023-12-11},
  abstract = {The star-structured high-order heterogeneous data is ubiquitous, such data represent objects of a certain type, connected to other types of data, or the features, so that the overall data schema forms a star-structure of inter-relationships. In this paper, we study the problem of co-clustering of star-structured high-order heterogeneous data. We present a new solution, a Hierarchical High-order Co-clustering Algorithm by Maximizing Modularity, MHCoC, which iteratively optimizes the objective function based on modularity and finally converges to a unique clustering result. In contrast to the traditional co-clustering methods, MHCoC merges information of multiple feature spaces of high-order heterogeneous data. Moreover, MHCoC takes a top-down strategy to perform a greedy divisive procedure, generating a tree-like hierarchical clustering result that reveal the relationship between clusters. To illustrate the process in more detail, we design a toy example to describe how MHCoC selects the appropriate co-cluster and splits it. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method.},
  langid = {english},
  keywords = {/unread,Co-clustering,Hierarchical structure,High-order heterogeneous data,Modularity},
  annotation = {影响因子: 5.6 5年影响因子: 4.5 abstractTranslation: 星型结构的高阶异构数据无处不在，这类数据表示某种类型的对象，连接到其他类型的数据，或特征，使得整体数据模式形成星型结构的相互关系。本文研究了星型结构高阶异构数据的共聚类问题。我们提出了一种新的解决方案，即基于最大化模块化的分层高阶共聚类算法MHCoC，该算法基于模块化迭代优化目标函数，最终收敛到独特的聚类结果。与传统的共聚类方法相比，MHCoC融合了高阶异构数据的多个特征空间的信息。此外，MHCoC采用自上而下的策略来执行贪婪的分裂过程，生成树状的分层聚类结果，揭示聚类之间的关系。为了更详细地说明该过程，我们设计了一个玩具示例来描述MHCoC如何选择适当的共簇并将其拆分。在真实数据集上进行了大量实验，验证了所提方法的有效性。},
  file = {/Volumes/Mac_Ext/Zotero/storage/H9XNMMH5/Wei et al. - 2021 - Hierarchical high-order co-clustering algorithm by maximizing modularity.pdf}
}
@article{hartigan1972DirectClusteringData,
  title = {Direct Clustering of a Data Matrix},
  author = {Hartigan, J. A.},
  date = {1972-03-01},
  journaltitle = {Journal of the American Statistical Association},
  volume = {67},
  number = {337},
  pages = {123--129},
  publisher = {Taylor \& Francis},
  issn = {0162-1459},
  doi = {10.1080/01621459.1972.10481214},
  url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1972.10481214},
  urldate = {2024-03-27},
  abstract = {Clustering algorithms are now in widespread use for sorting heterogeneous data into homogeneous blocks. If the data consist of a number of variables taking values over a number of cases, these algorithms may be used either to construct clusters of variables (using, say, correlation as a measure of distance between variables) or clusters of cases. This article presents a model, and a technique, for clustering cases and variables simultaneously. The principal advantage in this approach is the direct interpretation of the clusters on the data.},
  file = {/Volumes/Mac_Ext/Zotero/storage/88UXVDR6/Hartigan - 1972 - Direct clustering of a data matrix.pdf}
}
@inproceedings{nie2017LearningStructuredOptimal,
  title = {Learning a Structured Optimal Bipartite Graph for Co-Clustering},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Nie, Feiping and Wang, Xiaoqian and Deng, Cheng and Huang, Heng},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  date = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/00a03ec6533ca7f5c644d198d815329c-Paper.pdf},
  langid = {english},
  keywords = {/unread,⛔ No DOI found,nips,to follow,TODO},
  file = {/Volumes/Mac_Ext/Zotero/storage/BVLTH3XJ/Nie et al. - 2017 - Learning a structured optimal bipartite graph for co-clustering.pdf}
}
@article{cheng2015CoClusterDDistributedFramework,
  title = {Co-{{ClusterD}}: {{A}} Distributed Framework for Data Co-Clustering with Sequential Updates},
  shorttitle = {Co-{{ClusterD}}},
  author = {Cheng, Xiang and Su, Sen and Gao, Lixin and Yin, Jiangtao},
  date = {2015-12},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {27},
  number = {12},
  pages = {3231--3244},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2015.2451634},
  url = {https://ieeexplore.ieee.org/abstract/document/7145441},
  urldate = {2024-03-27},
  abstract = {Co-clustering has emerged to be a powerful data mining tool for two-dimensional co-occurrence and dyadic data. However, co-clustering algorithms often require significant computational resources and have been dismissed as impractical for large data sets. Existing studies have provided strong empirical evidence that expectation-maximization (EM) algorithms (e.g., k-means algorithm) with sequential updates can significantly reduce the computational cost without degrading the resulting solution. Motivated by this observation, we introduce sequential updates for alternate minimization co-clustering (AMCC) algorithms which are variants of EM algorithms, and also show that AMCC algorithms with sequential updates converge. We then propose two approaches to parallelize AMCC algorithms with sequential updates in a distributed environment. Both approaches are proved to maintain the convergence properties of AMCC algorithms. Based on these two approaches, we present a new distributed framework, Co-ClusterD, which supports efficient implementations of AMCC algorithms with sequential updates. We design and implement Co-ClusterD, and show its efficiency through two AMCC algorithms: fast nonnegative matrix tri-factorization (FNMTF) and information theoretic co-clustering (ITCC). We evaluate our framework on both a local cluster of machines and the Amazon EC2 cloud. Empirical results show that AMCC algorithms implemented in Co-ClusterD can achieve a much faster convergence and often obtain better results than their traditional concurrent counterparts.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {Algorithm design and analysis,Approximation algorithms,cloud computing,Cloud Computing,Clustering algorithms,Co-Clustering,concurrent updates,Concurrent Updates,Convergence,distributed framework,Distributed Framework,Linear programming,Minimization,Prototypes,sequential updates,Sequential Updates},
  file = {/Volumes/Mac_Ext/Zotero/storage/INTX2GR8/Cheng 等 - 2015 - Co-ClusterD A distributed framework for data co-clustering with sequential updates.pdf;/Volumes/Mac_Ext/Zotero/storage/WXFGE5JN/7145441.html}
}
@article{chen2023FastFlexibleBipartitea,
  title = {Fast {{Flexible Bipartite Graph Model}} for {{Co-Clustering}}},
  author = {Chen, Wei and Wang, Hongjun and Long, Zhiguo and Li, Tianrui},
  date = {2023-07},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {7},
  pages = {6930--6940},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2022.3194275},
  url = {https://ieeexplore.ieee.org/document/9842309},
  urldate = {2024-03-27},
  abstract = {Co-clustering methods make use of the correlation between samples and attributes to explore the co-occurrence structure in data. These methods have played a significant role in gene expression analysis, image segmentation, and document clustering. In bipartite graph partition-based co-clustering methods, the relationship between samples and attributes is described by constructing a diagonal symmetric bipartite graph matrix, which is clustered by the philosophy of spectral clustering. However, this not only has high time complexity but also the same number of row and column clusters. In fact, the number of categories of rows and columns often changes in the real world. To address these problems, this paper proposes a novel fast flexible bipartite graph model for the co-clustering method (FBGPC) that directly uses the original matrix to construct the bipartite graph. Then, it uses the inflation operation to partition the bipartite graph in order to learn the co-occurrence structure of the original data matrix based on the inherent relationship between bipartite graph partitioning and co-clustering. Finally, hierarchical clustering is used to obtain the clustering results according to the set relationship of the co-occurrence structure. Extensive empirical results show the effectiveness of our proposed model and verify the faster performance, generality, and flexibility of our model.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {Bipartite graph,bipartite graph partition,Clustering algorithms,Clustering methods,Co-clustering,Computational modeling,Data models,faster performance,flexibility,Partitioning algorithms,Time complexity},
  file = {/Volumes/Mac_Ext/Zotero/storage/KSAR6TWQ/Chen 等 - 2023 - Fast Flexible Bipartite Graph Model for Co-Clustering.pdf;/Volumes/Mac_Ext/Zotero/storage/SJBTPX4P/9842309.html}
}
@inproceedings{long2005CoclusteringBlockValue,
  title = {Co-Clustering by Block Value Decomposition},
  booktitle = {Knowledge {{Discovery}} and {{Data Mining}}},
  author = {Long, Bo and Zhang, Zhongfei (Mark) and Yu, Philip S.},
  date = {2005-08-21},
  series = {{{KDD}} '05},
  pages = {635--640},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/1081870.1081949},
  url = {https://dl.acm.org/doi/10.1145/1081870.1081949},
  urldate = {2023-05-02},
  abstract = {Dyadic data matrices, such as co-occurrence matrix, rating matrix, and proximity matrix, arise frequently in various important applications. A fundamental problem in dyadic data analysis is to find the hidden block structure of the data matrix. In this paper, we present a new co-clustering framework, block value decomposition(BVD), for dyadic data, which factorizes the dyadic data matrix into three components, the row-coefficient matrix R, the block value matrix B, and the column-coefficient matrix C. Under this framework, we focus on a special yet very popular case -- non-negative dyadic data, and propose a specific novel co-clustering algorithm that iteratively computes the three decomposition matrices based on the multiplicative updating rules. Extensive experimental evaluations also demonstrate the effectiveness and potential of this framework as well as the specific algorithms for co-clustering, and in particular, for discovering the hidden block structure in the dyadic data.动态数据矩阵，如共同发生矩阵、评级矩阵和接近矩阵，在各种重要应用中经常出现。动态数据分析的一个基本问题是找到数据矩阵的隐藏块结构。在本文中，我们提出了一个新的协同聚类框架，即针对动态数据的块值分解（BVD），它将动态数据矩阵分解为三个部分，即行系数矩阵R、块值矩阵B和列系数矩阵C。在这个框架下，我们专注于一个特殊但非常流行的情况--非负的动态数据，并提出了一个具体的新型共聚算法，该算法基于乘法更新规则，迭代计算三个分解矩阵。广泛的实验评估也证明了这一框架以及共同聚类的具体算法的有效性和潜力，特别是在发现动态数据中的隐藏块结构方面。},
  eventtitle = {{{ACM Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-59593-135-1},
  langid = {english},
  keywords = {⛔ No INSPIRE recid found,block value decomposition (BVD),clustering,co-clustering,dyadic data,hidden block structure,matrix decomposition,non-negative block value decomposition (NBVD),TODO},
  annotation = {107 citations (CrossRef 2024/1/23) titleTranslation: titleTranslation: titleTranslation: 南农核心: 无 南农高质量: 无 CCF: A},
  file = {/Volumes/Mac_Ext/Zotero/storage/U95TA7PH/Long et al. - 2005 - Co-clustering by block value decomposition.pdf}
}
